{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea9f3736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import ast\n",
    "import gensim\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0fb9df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all= pd.read_csv('All_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45ff54dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_title</th>\n",
       "      <th>2_way_label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>dic_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>differ order</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'differ': 1, 'order': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>concern sink tini hat</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>{'concern': 1, 'sink': 1, 'tini': 1, 'hat': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>leak ambassador</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'leak': 1, 'ambassador': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>puppi take view</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'puppi': 1, 'take': 1, 'view': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>face sheet music</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>{'face': 1, 'sheet': 1, 'music': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534209</th>\n",
       "      <td>bicycl taxi</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>{'bicycl': 1, 'taxi': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534210</th>\n",
       "      <td>trump win hous</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>{'trump': 1, 'win': 1, 'hous': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534211</th>\n",
       "      <td>napoleon island</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>{'napoleon': 1, 'island': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534212</th>\n",
       "      <td>deep dancer</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>{'deep': 1, 'dancer': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534213</th>\n",
       "      <td>toddler stori fall land car</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>{'toddler': 1, 'stori': 1, 'fall': 1, 'land': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534214 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        clean_title  2_way_label  word_count  \\\n",
       "0                      differ order            1           2   \n",
       "1             concern sink tini hat            0           4   \n",
       "2                   leak ambassador            1           2   \n",
       "3                   puppi take view            1           3   \n",
       "4                  face sheet music            0           3   \n",
       "...                             ...          ...         ...   \n",
       "534209                  bicycl taxi            1           2   \n",
       "534210               trump win hous            1           3   \n",
       "534211              napoleon island            0           2   \n",
       "534212                  deep dancer            0           2   \n",
       "534213  toddler stori fall land car            1           5   \n",
       "\n",
       "                                                dic_words  \n",
       "0                               {'differ': 1, 'order': 1}  \n",
       "1          {'concern': 1, 'sink': 1, 'tini': 1, 'hat': 1}  \n",
       "2                            {'leak': 1, 'ambassador': 1}  \n",
       "3                      {'puppi': 1, 'take': 1, 'view': 1}  \n",
       "4                     {'face': 1, 'sheet': 1, 'music': 1}  \n",
       "...                                                   ...  \n",
       "534209                           {'bicycl': 1, 'taxi': 1}  \n",
       "534210                  {'trump': 1, 'win': 1, 'hous': 1}  \n",
       "534211                       {'napoleon': 1, 'island': 1}  \n",
       "534212                           {'deep': 1, 'dancer': 1}  \n",
       "534213  {'toddler': 1, 'stori': 1, 'fall': 1, 'land': ...  \n",
       "\n",
       "[534214 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4edfb6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Label']=df_all['2_way_label']\n",
    "df_all['clean_title']=df_all['clean_title'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "215874de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_all.clean_title, df_all.Label, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32483cfb",
   "metadata": {},
   "source": [
    "# DOC2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cb024680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['paint', 'li', 'south', 'farm'], tags=['Train_0'])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_sent(corpus, lb_type):\n",
    "    labeled=[]\n",
    "    for i,v in enumerate(corpus):\n",
    "        lb1= lb_type+'_'+str(i)\n",
    "        labeled.append (gensim.models.doc2vec.TaggedDocument(v, [lb1]))\n",
    "    return labeled\n",
    "        \n",
    "X_train=label_sent(X_train, 'Train')\n",
    "X_test=label_sent(X_test, 'Test')\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6d45add6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['paint', 'li', 'south', 'farm'], tags=['Train_0'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data= X_train+ X_test\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9a9d3e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import utils\n",
    "model = gensim.models.doc2vec.Doc2Vec(dm=0, vector_size=300, negative=5,  min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model.build_vocab([x for x in all_data])\n",
    "for epoch in range(30):\n",
    "    model.train(utils.shuffle([x for x in all_data]), total_examples= len(all_data), epochs=1)\n",
    "    model.alpha-=0.002\n",
    "    model.min_alpha=model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "25c4becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(m, corp_sz, v_sz, v_type):\n",
    "    vectors= np.zeros((corp_sz,v_sz))\n",
    "    for i in range(0, corp_sz):\n",
    "        lb1= v_type + '_' + str(i)\n",
    "        vectors[i]=m.docvecs[lb1]\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "15daafbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABDELR~1\\AppData\\Local\\Temp/ipykernel_25184/3487055183.py:5: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  vectors[i]=m.docvecs[lb1]\n"
     ]
    }
   ],
   "source": [
    "train_vecs=get_vectors(model, len(X_train), 300, 'Train')\n",
    "test_vecs=get_vectors(model, len(X_test), 300, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "244dcc05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400660, 300)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4581aff3",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8aae9743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "clf=LogisticRegression(C=1e5)\n",
    "clf=clf.fit(train_vecs,y_train)\n",
    "yp=clf.predict(test_vecs)\n",
    "yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3caea0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71     70538\n",
      "           1       0.68      0.62      0.65     63016\n",
      "\n",
      "    accuracy                           0.68    133554\n",
      "   macro avg       0.68      0.68      0.68    133554\n",
      "weighted avg       0.68      0.68      0.68    133554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "becae8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71     70538\n",
      "           1       0.68      0.62      0.65     63016\n",
      "\n",
      "    accuracy                           0.68    133554\n",
      "   macro avg       0.68      0.68      0.68    133554\n",
      "weighted avg       0.68      0.68      0.68    133554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf=SGDClassifier(max_iter=100000)\n",
    "clf= clf.fit(train_vecs,y_train)\n",
    "yp=clf.predict(test_vecs)\n",
    "print(classification_report(y_test,yp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "23475d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAUSSIAN NB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.67     70538\n",
      "           1       0.62      0.52      0.56     63016\n",
      "\n",
      "    accuracy                           0.62    133554\n",
      "   macro avg       0.62      0.62      0.62    133554\n",
      "weighted avg       0.62      0.62      0.62    133554\n",
      "\n",
      "BERNOULLI NB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.67     70538\n",
      "           1       0.63      0.66      0.65     63016\n",
      "\n",
      "    accuracy                           0.66    133554\n",
      "   macro avg       0.66      0.66      0.66    133554\n",
      "weighted avg       0.66      0.66      0.66    133554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "print(\"GAUSSIAN NB\")\n",
    "naive_bayes_classifier = GaussianNB()\n",
    "naive_bayes_classifier= naive_bayes_classifier.fit(train_vecs, y_train)\n",
    "y_pred = naive_bayes_classifier.predict(test_vecs)\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "print(\"BERNOULLI NB\")\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(train_vecs,y_train)\n",
    "test_ber_doc2vec = bnb.predict(test_vecs)\n",
    "print(classification_report(y_test,test_ber_doc2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "790cf1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.56      0.60     70538\n",
      "           1       0.58      0.66      0.62     63016\n",
      "\n",
      "    accuracy                           0.61    133554\n",
      "   macro avg       0.61      0.61      0.61    133554\n",
      "weighted avg       0.62      0.61      0.61    133554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "Per_clf = Perceptron(tol=1e-3, random_state=0)\n",
    "Per_clf.fit(train_vecs,y_train)\n",
    "test_Per_doc2vec=Per_clf.predict(test_vecs)\n",
    "print(classification_report(y_test.values,test_Per_doc2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b55dc215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.74     70538\n",
      "           1       0.72      0.61      0.66     63016\n",
      "\n",
      "    accuracy                           0.70    133554\n",
      "   macro avg       0.71      0.70      0.70    133554\n",
      "weighted avg       0.71      0.70      0.70    133554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "NN = MLPClassifier(random_state=1, max_iter=5000)\n",
    "NN.fit(train_vecs,y_train.values)\n",
    "test_NN_doc2vec = NN.predict(test_vecs)\n",
    "print(classification_report(y_test.values,test_NN_doc2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ca710114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62     70538\n",
      "           1       0.57      0.57      0.57     63016\n",
      "\n",
      "    accuracy                           0.60    133554\n",
      "   macro avg       0.59      0.59      0.59    133554\n",
      "weighted avg       0.60      0.60      0.60    133554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_decision_doc2vec = DecisionTreeClassifier()\n",
    "clf_decision_doc2vec.fit(train_vecs,y_train)\n",
    "test_predictions_doc2vec = clf_decision_doc2vec.predict(test_vecs)\n",
    "print(classification_report(y_test,test_predictions_doc2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "079d0418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.75      0.71     70538\n",
      "           1       0.68      0.60      0.64     63016\n",
      "\n",
      "    accuracy                           0.68    133554\n",
      "   macro avg       0.68      0.68      0.68    133554\n",
      "weighted avg       0.68      0.68      0.68    133554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(train_vecs,y_train)\n",
    "test_predictions_w2vec = clf.predict(test_vecs)\n",
    "print(classification_report(y_test,test_predictions_w2vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2c888b",
   "metadata": {},
   "source": [
    "# WORD2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5736b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_all.clean_title, df_all.Label, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d303401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400660,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e89ab7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "titles_corpus= []\n",
    "for title in df_all[\"dic_words\"][:]:\n",
    "    new_list = list(ast.literal_eval(title).keys())\n",
    "    if (new_list != []):\n",
    "        titles_corpus.append(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2e8a2f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['differ', 'order'],\n",
       " ['concern', 'sink', 'tini', 'hat'],\n",
       " ['leak', 'ambassador'],\n",
       " ['puppi', 'take', 'view'],\n",
       " ['face', 'sheet', 'music'],\n",
       " ['bride', 'exchang', 'fatal', 'shoot', 'we', 'd'],\n",
       " ['meat', 'pig', 'eat', 'milk'],\n",
       " ['convert', 'local', 'teen', 'circa', 'ad'],\n",
       " ['victori', 'great', 'crusad'],\n",
       " ['villag', 'leader', 'clean', 'patch'],\n",
       " ['ai', 'fli', 'moon'],\n",
       " ['seven', 'sloth'],\n",
       " ['babi', 'cow', 'see', 'head', 'day', 'enjoy'],\n",
       " ['girl', 'wear', 'virtual', 'realiti', 'hold'],\n",
       " ['way', 'rain', 'silhouett', 'bike'],\n",
       " ['mental', 'ill', 'easi'],\n",
       " ['love', 'peac', 'way', 'soviet', 'union'],\n",
       " ['view', 'bar', 'palac'],\n",
       " ['goe', 'well', 'red', 'white', 'rememb'],\n",
       " ['happi', 'boat'],\n",
       " ['tree', 'angri', 'fall'],\n",
       " ['governor', 'statement', 'interview'],\n",
       " ['join', 'communist', 'parti', 'music', 'video', 'w'],\n",
       " ['neighbor', 'ambul', 'compani', 'move', 'get'],\n",
       " ['creepi', 'guy', 'hair', 'stare'],\n",
       " ['rain', 'iron', 'wall', 'beauti', 'red'],\n",
       " ['presid', 'make', 'point', 'parliament'],\n",
       " ['final', 'come', 'steam', 'there', 'big', 'catch'],\n",
       " ['loo', 'truck'],\n",
       " ['quick', 'obviou'],\n",
       " ['happi', 'rental'],\n",
       " ['shape', 'squar'],\n",
       " ['sun', 'bear', 'sit', 'x'],\n",
       " ['sure', 'feel'],\n",
       " ['car', 'door', 'bolt'],\n",
       " ['cut', 'old', 'tree', 'recent', 'album'],\n",
       " ['el', 'prison', 'th'],\n",
       " ['light', 'desk'],\n",
       " ['spike', 'lee', 'sam'],\n",
       " ['screen', 'museum'],\n",
       " ['report', 'posit', 'gain', 'role', 'lord'],\n",
       " ['danc'],\n",
       " ['quit', 'hor'],\n",
       " ['comfort', 'foster', 'child', 'care'],\n",
       " ['leaf', 'shape'],\n",
       " ['tattoo', 'artist', 'cover', 'peopl', 'self', 'free'],\n",
       " ['littl', 'guy', 'stick', 'snow'],\n",
       " ['we', 'd', 'bark'],\n",
       " ['cabl', 'compani', 'hate', 'know', 'tell', 'devic'],\n",
       " ['there', 'girl', 'pictur'],\n",
       " ['differ', 'light'],\n",
       " ['fish', 'aquarium'],\n",
       " ['ca', 'long', 'ago', 'date', 'unknown'],\n",
       " ['fli', 'free', 'world', 'strike', 'leaflet'],\n",
       " ['entir', 'sure', 'go'],\n",
       " ['keyboard', 'light', 'scale'],\n",
       " ['futur'],\n",
       " ['park'],\n",
       " ['cop', 'bring', 'request', 'traffic', 'stop'],\n",
       " ['want', 'ice', 'cream'],\n",
       " ['what', 'wor', 'piano', 'organ'],\n",
       " ['perfect', 'photo'],\n",
       " ['enjoy', 'view'],\n",
       " ['king'],\n",
       " ['creatur', 'want', 'heat', 'good', 'music'],\n",
       " ['condit', 'form'],\n",
       " ['trophi', 'good', 'corn'],\n",
       " ['ident'],\n",
       " ['basketbal', 'game', 'auction', 'pig'],\n",
       " ['spider', 'porch', 'stick', 'fool', 'prey'],\n",
       " ['copper', 'turn', 'green', 'pair', 'right', 'comparison'],\n",
       " ['way', 'spiral', 'burn'],\n",
       " ['great', 'crusad'],\n",
       " ['get', 'shoot', 'murder'],\n",
       " ['die', 'bee', 'park', 'grill', 'onion'],\n",
       " ['car', 'control'],\n",
       " ['otter', 'go', 'slide'],\n",
       " ['pregnant', 'manag', 'fire', 'pay', 'arm', 'robberi'],\n",
       " ['iceland'],\n",
       " ['friendli', 'neighborhood', 'mayor'],\n",
       " ['eat', 'fresh', 'appl', 'insid'],\n",
       " ['lose', 'nose', 'way', 'workplac'],\n",
       " ['talk', 'son'],\n",
       " ['despit', 'lead', 'remain', 'campaign'],\n",
       " ['ride', 'weird', 'guy'],\n",
       " ['tri', 'sneak'],\n",
       " ['rock', 'air', 'jordan'],\n",
       " ['candi', 'giant', 'protect'],\n",
       " ['smell'],\n",
       " ['footbal', 'squad', 'celebr', 'goal', 'world', 'cup'],\n",
       " ['receiv', 'today'],\n",
       " ['boston', 'donat', 'blood'],\n",
       " ['job'],\n",
       " ['paper', 'guid', 'good', 'day'],\n",
       " ['pay', 'visit', 'join', 'battl', 'net', 'neutral'],\n",
       " ['rare', 'use', 'stapler', 'guess', 'accur', 'sloth'],\n",
       " ['probabl', 'congress'],\n",
       " ['well', 'late'],\n",
       " ['mind', 'busi', 'work', 'take', 'goofi', 'guy', 'smile'],\n",
       " ['emperor', 'brazil', 'art'],\n",
       " ['sex', 'roof', 'human', 'shield', 'bridg'],\n",
       " ['groceri'],\n",
       " ['shoot', 'downtown', 'near', 'scene'],\n",
       " ['kitti', 'small', 'face'],\n",
       " ['fall', 'asleep', 'remot'],\n",
       " ['hide', 'lake', 'mountain', 'nation', 'park', 'montana'],\n",
       " ['pictur'],\n",
       " ['hedgehog', 'golden', 'retriev', 'wear'],\n",
       " ['that', 'hair'],\n",
       " ['box'],\n",
       " ['tree', 'split', 'right', 'open'],\n",
       " ['sleep', 'roof'],\n",
       " ['read',\n",
       "  'news',\n",
       "  'well',\n",
       "  'check',\n",
       "  'free',\n",
       "  'dad',\n",
       "  'daughter',\n",
       "  'hair',\n",
       "  'class',\n",
       "  'thank'],\n",
       " ['newli'],\n",
       " ['union', 'friendship', 'poster', 'communist', 'parti'],\n",
       " ['feder', 'judg', 'day'],\n",
       " ['show', 'mission', 'land'],\n",
       " ['father', 'son', 'outfit'],\n",
       " ['soldier', 'charg', 'german'],\n",
       " ['toddler', 'sheep', 'play', 'babi', 'nativ'],\n",
       " ['fire'],\n",
       " ['know', 'real'],\n",
       " ['shock', 'news'],\n",
       " ['happi'],\n",
       " ['histor', 'footag', 'serv', 'countri'],\n",
       " ['melt', 'car'],\n",
       " ['fur', 'black', 'snow', 'white'],\n",
       " ['get'],\n",
       " ['robot', 'dig', 'red', 'planet', 'week'],\n",
       " ['toilet', 'paper', 'leave', 'long', 'right'],\n",
       " ['girl'],\n",
       " ['amaz', 'san', 'garden', 'experi'],\n",
       " ['heavi', 'end', 'empir'],\n",
       " ['beer', 'awesom'],\n",
       " ['ride'],\n",
       " ['happi', 'frog'],\n",
       " ['stamp', 'perfectli', 'creat', 'cool', 'pattern'],\n",
       " ['sad', 'jordan', 'sorri'],\n",
       " ['coffe', 'color', 'cup'],\n",
       " ['mous', 'power', 'line', 'pole'],\n",
       " ['art', 'record', 'album'],\n",
       " ['gang', 'violenc'],\n",
       " ['wake', 'polic', 'woman'],\n",
       " ['tunnel', 'north', 'nuclear', 'test'],\n",
       " ['singl', 'give'],\n",
       " ['love', 'club'],\n",
       " ['guy', 'life', 'pressur'],\n",
       " ['wor'],\n",
       " ['head', 'gate'],\n",
       " ['flag'],\n",
       " ['lizard', 'pool'],\n",
       " ['major', 'democrat', 'donor', 'run', 'drug'],\n",
       " ['red', 'soldier', 'experi', 's', 'war', 'news', 'report'],\n",
       " ['bunni', 'lose', 'space'],\n",
       " ['tower', 'zone', 'map'],\n",
       " ['complet', 'independ', 'feel'],\n",
       " ['guardian', 'babi'],\n",
       " ['coffe', 'awesom'],\n",
       " ['demonstr'],\n",
       " ['arm', 'protect', 'bag', 'cold', 'dead'],\n",
       " ['young', 'peopl', 'see', 'real', 'cow'],\n",
       " ['bear', 'leg', 'knee', 'face', 'side', 'fun', 'parti', 'trick'],\n",
       " ['save'],\n",
       " ['c', 'steal'],\n",
       " ['girl', 'head', 'soccer', 'ball'],\n",
       " ['quiz', 'fall', 'death'],\n",
       " ['bowl', 'build', 'holder'],\n",
       " ['order', 'york', 'offic', 'involv', 'hous', 'intellig', 'committe'],\n",
       " ['lamp', 'physic', 'surfac', 'moon'],\n",
       " ['exit', 'enter'],\n",
       " ['come', 'peac'],\n",
       " ['crack', 'open', 'paint'],\n",
       " ['bring'],\n",
       " ['axi', 'wage', 'poster', 'district'],\n",
       " ['stand', 'good', 'pictur'],\n",
       " ['end', 'line', 'crisi'],\n",
       " ['attempt', 'remov'],\n",
       " ['eu', 'seek', 'asylum'],\n",
       " ['intern', 'space', 'station', 'astronaut', 'canada'],\n",
       " ['tell', 'good', 'final', 'get', 'traffic', 'sign'],\n",
       " ['watch', 'date'],\n",
       " ['day', 'umbrella', 'feel', 'littl'],\n",
       " ['russia'],\n",
       " ['apolog', 'say', 'queen', 'vote', 'result'],\n",
       " ['troll', 'judg', 'order', 'silenc'],\n",
       " ['go', 'bathroom'],\n",
       " ['trump', 'administr', 'threaten', 'releas', 'privat', 'foreign'],\n",
       " ['post', 'game', 'thread', 'ti', 'middl', 'vintag'],\n",
       " ['japan', 'pearl'],\n",
       " ['good', 'career', 'advic', 'get'],\n",
       " ['self', 'titl'],\n",
       " ['rubber', 'pool'],\n",
       " ['big', 'chunk', 'peanut', 'butter', 'box', 'morn'],\n",
       " ['know'],\n",
       " ['way', 'golden', 'hour'],\n",
       " ['final', 'club', 'championship', 'tri'],\n",
       " ['rare', 'photo', 'parti', 'member', 'read', 'circa'],\n",
       " ['shadow', 'bike', 'rain'],\n",
       " ['guess', 'start'],\n",
       " ['child', 'leave'],\n",
       " ['villain', 'concept', 'art'],\n",
       " ['door', 'neighbor'],\n",
       " ['enjoy', 'cake', 'day'],\n",
       " ['raw'],\n",
       " ['wind', 'solar', 'power', 'prevent'],\n",
       " ['home', 'grow', 'eggplant'],\n",
       " ['see', 'ga', 'station', 'middl', 'water'],\n",
       " ['frog', 'get', 'eat', 'snake'],\n",
       " ['desert'],\n",
       " ['think'],\n",
       " ['sir'],\n",
       " ['notic', 'sweater'],\n",
       " ['mother'],\n",
       " ['mall', 'there', 'power', 'outlet', 'ceil'],\n",
       " ['ti', 'poster'],\n",
       " ['guy', 'tri', 'drink', 'waterfal'],\n",
       " ['wild', 'ani'],\n",
       " ['plant', 'pilot', 'air', 'fleet', 's'],\n",
       " ['shop', 'cart'],\n",
       " ['toilet', 'paper', 'secur', 'level', 'master', 'lock'],\n",
       " ['use', 'deadli', 'forc', 'polic', 'street'],\n",
       " ['late', 'winter', 'fashion', 'trend'],\n",
       " ['start', 'littl'],\n",
       " ['perfect', 'sand', 'ball'],\n",
       " ['big', 'kitti', 'ball', 'pit'],\n",
       " ['float', 'resort', 'situat'],\n",
       " ['sit', 'lap'],\n",
       " ['friend', 'sack', 'lunch'],\n",
       " ['actual', 'idea', 'sit'],\n",
       " ['babi'],\n",
       " ['discov', 'alien', 'plant', 'hybrid'],\n",
       " ['deliv'],\n",
       " ['tree', 'metal', 'guard'],\n",
       " ['sock'],\n",
       " ['concern', 'citizen', 'question'],\n",
       " ['tree'],\n",
       " ['that', 'hand'],\n",
       " ['go', 'brand', 'store', 'today', 'east', 'coast'],\n",
       " ['war'],\n",
       " ['cathedr', 'holi', 'centuri'],\n",
       " ['ice', 'end', 'today'],\n",
       " ['skip', 'nuclear', 'ban', 'treati'],\n",
       " ['milk', 'dispen', 'airport'],\n",
       " ['statu', 'museum'],\n",
       " ['pictur', 'drink', 'beer'],\n",
       " ['statu', 'boy', 'ride', 'bike'],\n",
       " ['trump', 'ai', 'al'],\n",
       " ['coat', 'sugar'],\n",
       " ['lift'],\n",
       " ['north', 'travel', 'ban'],\n",
       " ['get', 'tail'],\n",
       " ['haircut'],\n",
       " ['tri', 'stop', 'hi'],\n",
       " ['pigeon', 'miss', 'finger'],\n",
       " ['red', 'cross', 'm', 'benefit', 'concert', 'total'],\n",
       " ['giant'],\n",
       " ['insid', 'floor', 'build', 'ceil'],\n",
       " ['hug'],\n",
       " ['circa'],\n",
       " ['guy', 'eat', 'birthday', 'meal', 'x'],\n",
       " ['rock', 'paint', 'yellow'],\n",
       " ['ca', 'handl'],\n",
       " ['custom', 'polit', 'lawyer'],\n",
       " ['chang', 'stay'],\n",
       " ['squat', 'glass', 'bottl'],\n",
       " ['ride'],\n",
       " ['plane', 'say', 'need', 'help', 'video'],\n",
       " ['bad'],\n",
       " ['final', 'spice'],\n",
       " ['trade', 'war', 'lobster', 'industri', 'peak', 'season'],\n",
       " ['stand', 'shelf', 'hold', 'huge'],\n",
       " ['squat'],\n",
       " ['near', 'bubbl', 'resort', 'jordan'],\n",
       " ['pictur'],\n",
       " ['pure', 'rock'],\n",
       " ['way'],\n",
       " ['freezer', 'conden', 'glue', 'littl', 'plastic', 'come'],\n",
       " ['citi', 'intern', 'space', 'station'],\n",
       " ['guy', 'patient', 'wait', 'phone'],\n",
       " ['pictur', 'take', 'photo'],\n",
       " ['south'],\n",
       " ['bush', 'invas', 'congress'],\n",
       " ['obligatori', 'edit'],\n",
       " ['flash', 'movi', 'get'],\n",
       " ['airport', 'garag', 'fun', 'weekend'],\n",
       " ['cold'],\n",
       " ['girl', 'tri', 'pay', 'colleg'],\n",
       " ['state', 'senior', 'citizen'],\n",
       " ['palm', 'unit', 'space', 'intern', 'station', 'astronaut'],\n",
       " ['curiou'],\n",
       " ['interview'],\n",
       " ['extrem', 'court', 'end', 'day'],\n",
       " ['rival', 'footbal', 'work', 'allow', 'score'],\n",
       " ['secret', 'life'],\n",
       " ['distress', 'creatur', 'ice', 'cream'],\n",
       " ['emperor', 'empir', 'support', 'run', 'minist', 'c', 'ad'],\n",
       " ['need'],\n",
       " ['small', 'town', 'train'],\n",
       " ['steal', 'laundri'],\n",
       " ['miss', 'ti', 'fort'],\n",
       " ['win', 'lotteri'],\n",
       " ['paw', 'patrol'],\n",
       " ['attack'],\n",
       " ['cook', 'dinner'],\n",
       " ['color'],\n",
       " ['outfit'],\n",
       " ['young', 'gay', 'coupl', 'good', 'boy'],\n",
       " ['outsid'],\n",
       " ['everybodi'],\n",
       " ['blanket', 'boat'],\n",
       " ['colin', 'footbal'],\n",
       " ['rescu', 'team', 'miss', 'aliv'],\n",
       " ['hey', 'huh', 'yeah', 'super', 'cool'],\n",
       " ['sandwich', 'press'],\n",
       " ['right'],\n",
       " ['cardboard', 'littl', 'hurrican', 'survivor'],\n",
       " ['guy', 'natur', 'stick', 'fire'],\n",
       " ['shoot', 'blue', 'right', 'break', 'format'],\n",
       " ['beauti', 'color', 'feather'],\n",
       " ['drink', 'warm', 'juic', 'day'],\n",
       " ['terribl', 'person'],\n",
       " ['know', 'die', 'mate', 'want', 'jump', 'glass', 'desk'],\n",
       " ['senat', 'exist'],\n",
       " ['seal', 'excit', 'girl'],\n",
       " ['ca', 'oh', 'wait', 'that'],\n",
       " ['toddler', 'enjoy', 'afternoon', 'mother'],\n",
       " ['innoc', 'surviv'],\n",
       " ['aerial', 'view', 'footbal', 'stadium'],\n",
       " ['feel', 'watch'],\n",
       " ['come', 'sweet', 'tooth'],\n",
       " ['ride'],\n",
       " ['friendli', 'game', 'golf'],\n",
       " ['towel', 'hook', 'bathroom'],\n",
       " ['good', 'day'],\n",
       " ['moo', 'see', 'float', 'lone', 'north', 'river'],\n",
       " ['troll'],\n",
       " ['peopl', 'drop', 'diet', 'coke', 'si'],\n",
       " ['s', 'soviet', 'poster', 'road', 'commun'],\n",
       " ['head'],\n",
       " ['was'],\n",
       " ['polic',\n",
       "  'search',\n",
       "  'marijuana',\n",
       "  'stage',\n",
       "  'cancer',\n",
       "  'hospit',\n",
       "  'room',\n",
       "  'viral',\n",
       "  'video'],\n",
       " ['geniu', 'billionair'],\n",
       " ['forc', 'prison', 'train', 'bind'],\n",
       " ['black', 'son', 'bear', 'white'],\n",
       " ['mirror'],\n",
       " ['bill', 'give', 'speech'],\n",
       " ['lamb', 'investig'],\n",
       " ['goat', 'wear', 'crown', 'king'],\n",
       " ['speed', 'old', 'hous'],\n",
       " ['boston', 'suspect', 'accord', 'fox', 'news'],\n",
       " ['local', 'amaz'],\n",
       " ['track'],\n",
       " ['white',\n",
       "  'hous',\n",
       "  'nation',\n",
       "  'freedom',\n",
       "  'inform',\n",
       "  'day',\n",
       "  'make',\n",
       "  'offic',\n",
       "  'administr',\n",
       "  'complet'],\n",
       " ['restaur', 'china', 'arcad', 'machin', 'play', 'free'],\n",
       " ['polic', 'end', 'use', 'scene'],\n",
       " ['machin'],\n",
       " ['detail',\n",
       "  'pictur',\n",
       "  'presid',\n",
       "  'j',\n",
       "  'peni',\n",
       "  'take',\n",
       "  'advanc',\n",
       "  'spi',\n",
       "  'camera',\n",
       "  'stormi'],\n",
       " ['bark'],\n",
       " ['valley', 'fall'],\n",
       " ['date', 'soviet', 'union'],\n",
       " ['circa'],\n",
       " ['cash', 'al'],\n",
       " ['twitter', 'modern', 'warfar'],\n",
       " ['grow'],\n",
       " ['guy', 'bit'],\n",
       " ['spider'],\n",
       " ['pictur', 'clear', 'landscap', 'pollut'],\n",
       " ['target', 'phoenix', 'polic', 'hous'],\n",
       " ['leave', 'red', 'towel', 'white'],\n",
       " ['larri', 'lose', 'fantasi', 'footbal', 'sit', 'hi'],\n",
       " ['think', 'nap', 'ti'],\n",
       " ['tell', 'medium'],\n",
       " ['sunris'],\n",
       " ['see', 'truck', 'drive', 'town', 'day'],\n",
       " ['control'],\n",
       " ['north', 'product'],\n",
       " ['commun', 'colleg', 'competit'],\n",
       " ['ask'],\n",
       " ['peopl', 'turn', 'circa'],\n",
       " ['come', 'young', 'fan', 'hand', 'throw', 'pitch'],\n",
       " ['larg', 'seat', 'bench'],\n",
       " ['brother', 'world', 'famou'],\n",
       " ['sue', 'disast', 'relief'],\n",
       " ['suicid', 'ride'],\n",
       " ['beach', 'southern', 'bridg', 'east'],\n",
       " ['slow', 'industri', 'worker'],\n",
       " ['danc'],\n",
       " ['fog'],\n",
       " ['good'],\n",
       " ['s', 'good', 'date'],\n",
       " ['leave', 'dead', 'plastic', 'bag', 'girl', 'colleg'],\n",
       " ['butterfli', 'fresh'],\n",
       " ['war', 'circa', 'ad'],\n",
       " ['good', 'old', 'day'],\n",
       " ['babi', 'bear', 'skull', 'miss', 'birthday'],\n",
       " ['creator'],\n",
       " ['north', 'high', 'mountain'],\n",
       " ['sing', 'song'],\n",
       " ['game', 'win', 'way'],\n",
       " ['ago', 'today'],\n",
       " ['press', 'start', 'play'],\n",
       " ['trump'],\n",
       " ['accus', 'cut'],\n",
       " ['pope'],\n",
       " ['way', 'light'],\n",
       " ['univer', 'bu', 'thumb', 'drive'],\n",
       " ['f', 'chat', 'shirt'],\n",
       " ['parad', 'arch', 'nation', 'park'],\n",
       " ['prepar', 'pyramid'],\n",
       " ['sad', 'clown'],\n",
       " ['spare'],\n",
       " ['guy', 'butt'],\n",
       " ['littl'],\n",
       " ['year', 'old', 'girl'],\n",
       " ['coin', 'yard'],\n",
       " ['concert'],\n",
       " ['frog', 'mouth'],\n",
       " ['mother', 'puppi', 'seat', 'car'],\n",
       " ['target', 'park', 'lot', 'close'],\n",
       " ['massiv', 'packag'],\n",
       " ['sun'],\n",
       " ['problem', 'citi'],\n",
       " ['relationship', 'disgust', 'consid', 'scar', 'life', 'hear', 'disturb'],\n",
       " ['there', 'golden', 'west', 'joke'],\n",
       " ['flash', 'action'],\n",
       " ['babi'],\n",
       " ['trump'],\n",
       " ['recent'],\n",
       " ['hi', 'young', 'actor', 'circa', 's'],\n",
       " ['plastic', 'pumpkin'],\n",
       " ['white', 'yellow', 'slightli', 'right', 'eye'],\n",
       " ['doggi', 'treat'],\n",
       " ['feed'],\n",
       " ['suprem'],\n",
       " ['big', 'wheel'],\n",
       " ['oddli'],\n",
       " ['turtl'],\n",
       " ['colonel', 'sander', 'stand', 'pictur'],\n",
       " ['nearli', 'punish', 'popular'],\n",
       " ['gulf'],\n",
       " ['charact', 'act'],\n",
       " ['grow'],\n",
       " ['hair', 'cut'],\n",
       " ['fun', 'attempt'],\n",
       " ['come', 'soon'],\n",
       " ['watch'],\n",
       " ['littl', 'room'],\n",
       " ['king'],\n",
       " ['eat', 'today'],\n",
       " ['trump', 'toddler', 'get', 'lose', 'white', 'hous'],\n",
       " ['legend'],\n",
       " ['cloud', 'see', 'day'],\n",
       " ['human'],\n",
       " ['burn', 'free'],\n",
       " ['sugar', 'mouth'],\n",
       " ['come', 'fun'],\n",
       " ['oh', 'know'],\n",
       " ['militari', 'consid', 'food', 'north', 'away', 'nuclear'],\n",
       " ['papa'],\n",
       " ['seek'],\n",
       " ['come', 'fine', 'neutral'],\n",
       " ['daughter', 'movi', 'night'],\n",
       " ['propos', 'pact'],\n",
       " ['trump', 'reform'],\n",
       " ['rain'],\n",
       " ['idea'],\n",
       " ['materi', 'build', 'modern', 'world', 'fix'],\n",
       " ['hous', 'want', 'know', 'major', 'case', 'settl'],\n",
       " ['invas', 'fill', 'emerg', 'storag', 'live'],\n",
       " ['ceil', 'origin'],\n",
       " ['think', 'dead'],\n",
       " ['ask', 'eu', 'date'],\n",
       " ['nude', 'sculptur'],\n",
       " ['make', 'dinner'],\n",
       " ['island', 'rocket', 'launch', 'tri'],\n",
       " ['small', 'melt', 'televis'],\n",
       " ['teacher', 'feed'],\n",
       " ['format', 'battl', 'el'],\n",
       " ['angri', 'hedgehog', 'couch', 'big', 'version'],\n",
       " ['singl', 'tini', 'cloud', 'clear', 'sky', 'grand', 'canyon'],\n",
       " ['ice',\n",
       "  'cream',\n",
       "  'come',\n",
       "  'insid',\n",
       "  'fruit',\n",
       "  'shell',\n",
       "  'instead',\n",
       "  'paper',\n",
       "  'cup'],\n",
       " ['basebal', 'card', 'closet', 'away', 's'],\n",
       " ['peopl', 'armi', 'warn', 'modern', 'date', 'na'],\n",
       " ['li', 'edit', 'bag'],\n",
       " ['bath'],\n",
       " ['photo', 'grandpa', 'turn', 'purpl'],\n",
       " ['alli', 'land', 'beach', 'th'],\n",
       " ['know', 'eleph', 'warrior', 'return', 'king'],\n",
       " ['elect', 'server', 'suit'],\n",
       " ['militari', 'german', 'left', 'parti', 'sticker', 'berlin', 'translat'],\n",
       " ['pic'],\n",
       " ['meet', 'neighbor', 'ti'],\n",
       " ['littl', 'girl', 'stand', 'rainbow'],\n",
       " ['stuf', 'dinosaur', 'trailer'],\n",
       " ['cover', 'tin'],\n",
       " ['round', 'power'],\n",
       " ['extra', 'tooth'],\n",
       " ['wolf', 'dead'],\n",
       " ['safe', 'seal', 'museum', 'spin', 'lock', 'random'],\n",
       " ['leave', 'write', 'left', 'shoe', 'right'],\n",
       " ['electron', 'cigarett', 'enjoy'],\n",
       " ['soviet', 'turn', 'soldier', 'c'],\n",
       " ['spend', 'poor', 'unfortun'],\n",
       " ['sky', 'panel', 'ceil', 'servic', 'station', 'bathroom'],\n",
       " ['let', 'world', 'consum'],\n",
       " ['girl', 'beat', 'high', 'cast', 'shadow', 'fall', 'famili'],\n",
       " ['hair'],\n",
       " ['famou', 'photo', 'stand'],\n",
       " ['gay'],\n",
       " ['polit', 'parti', 'great', 'depress'],\n",
       " ['piec', 'w', 'demonstr', 'perspect'],\n",
       " ['search', 'true'],\n",
       " ['fear', 'atom', 'energi'],\n",
       " ['fight'],\n",
       " ['charg', 'german', 'machin', 'gun', 'fire', 'c'],\n",
       " ['candi', 'energi'],\n",
       " ['bed', 'stage', 'fake'],\n",
       " ['democrat', 'circa'],\n",
       " ['room'],\n",
       " ['snail', 'crawl', 'line'],\n",
       " ['there', 'engin'],\n",
       " ['pride'],\n",
       " ['brave', 'destroy'],\n",
       " ['hand'],\n",
       " ['kiss'],\n",
       " ['floor'],\n",
       " ['war', 'region'],\n",
       " ['pictur', 'princ', 'nick', 'pink'],\n",
       " ['good', 'work', 'sister', 'figur', 'job', 'meet', 'test', 'unit'],\n",
       " ['throne'],\n",
       " ['way', 'sit'],\n",
       " ['lot', 'navi', 'vet', 'rais', 'awar', 'veteran', 'suicid', 'homeless'],\n",
       " ['piec', 'paper', 'high', 'school'],\n",
       " ['shed', 'fight', 'date'],\n",
       " ['edit', 'book', 'beauti', 'art', 'true'],\n",
       " ['owl', 'bathroom', 'door'],\n",
       " ['white', 'clean'],\n",
       " ['cute', 'happi', 'smoke', 'alarm'],\n",
       " ['shadow', 'glori'],\n",
       " ['way', 'measur', 'cup', 'stick', 'age', 'past', 'decad'],\n",
       " ['iron', 'terror'],\n",
       " ['reaction', 'hat'],\n",
       " ['devast', 'volcano', 'erupt'],\n",
       " ['copi'],\n",
       " ['fake', 'news'],\n",
       " ['jake', 'shut', 'confer'],\n",
       " ['fast', 'furiou'],\n",
       " ['girl', 'mount'],\n",
       " ['date', 'unknown', 'forward', 'path', 'commun'],\n",
       " ['war', 'poster'],\n",
       " ['charact', 'real'],\n",
       " ['mutant'],\n",
       " ['sad', 'robot'],\n",
       " ['german', 'prepar', 'gay', 'shoot'],\n",
       " ['cape', 'throw', 'hurrican', 'florenc', 'peopl'],\n",
       " ['silli', 'fli'],\n",
       " ['musk', 'dolphin', 'work'],\n",
       " ['direct'],\n",
       " ['bob'],\n",
       " ['fight'],\n",
       " ['clearli', 'mind'],\n",
       " ['soon'],\n",
       " ['sweet'],\n",
       " ['color', 'sea', 'snail', 'shell'],\n",
       " ['carl'],\n",
       " ['day', 'final'],\n",
       " ['kitten', 'van'],\n",
       " ['lone'],\n",
       " ['piec'],\n",
       " ['cruis', 'ship', 'sail', 'small', 'exit', 'floor', 'dollar', 'scale'],\n",
       " ['local', 'villag', 'turn', 'old', 'telephon', 'box', 'book', 'swap'],\n",
       " ['obviou', 'spi'],\n",
       " ['miss', 'confeder', 'flag', 'polic'],\n",
       " ['think', 'lose', 'half', 'tail'],\n",
       " ['seri', 'base', 'hous', 'jack', 'build', 'parliament'],\n",
       " ['black', 'emperor', 'fly', 'templ'],\n",
       " ['hang', 'thread', 'place', 'lie', 'head'],\n",
       " ['take'],\n",
       " ['breweri', 'effort', 'help', 'rais', 'money', 'homeless'],\n",
       " ['rule', 'appli'],\n",
       " ['crew', 'board', 'main', 'collect', 'chee', 'moon'],\n",
       " ['smoke', 'son', 'colleg', 'cheat', 'rap'],\n",
       " ['pictur', 'coupl', 'milk', 'carton', 'kitchen'],\n",
       " ['build', 'stab', 'robot'],\n",
       " ['rare', 'photo', 'take', 'atom', 'bomb', 'hit', 'citi', 'ama'],\n",
       " ['good', 'cop'],\n",
       " ['water', 'scream', 'skull'],\n",
       " ['guy', 'see'],\n",
       " ['light'],\n",
       " ['happi', 'littl'],\n",
       " ['know'],\n",
       " ['drive', 'think', 'come', 'get', 'home'],\n",
       " ['quick', 'smith', 'jeff'],\n",
       " ['memori', 'prefer', 'terror', 'x'],\n",
       " ['throw', 'concret', 'wall'],\n",
       " ['perfect', 'photo'],\n",
       " ['sight', 'catch', 'camera'],\n",
       " ['graduat', 'photo'],\n",
       " ['warn'],\n",
       " ['suprem', 'leader'],\n",
       " ['tomato', 'piec', 'frog'],\n",
       " ['univer', 'newspap', 'offen'],\n",
       " ['worri'],\n",
       " ['friendli', 'alien', 'face', 'tube'],\n",
       " ['north', 'nuclear'],\n",
       " ['alli', 'begin'],\n",
       " ['poster', 'easter', 'rise'],\n",
       " ['i', 'd', 'face', 'giant', 'eat'],\n",
       " ['drop', 'water', 'form', 'perfect', 'shape'],\n",
       " ['hi', 'yellow'],\n",
       " ['death', 'sheriff', 'rule'],\n",
       " ['veteran', 'puppi', 'apart'],\n",
       " ['home', 'rent', 'page'],\n",
       " ['skate'],\n",
       " ['babi', 'fish'],\n",
       " ['alli', 'secret', 'weapon', 'war'],\n",
       " ['battl'],\n",
       " ['star'],\n",
       " ['bumper', 'sticker', 'car'],\n",
       " ['lucki', 'ti', 'feed'],\n",
       " ['come', 'bare', 'foot'],\n",
       " ['phone', 'happi'],\n",
       " ['north', 'mushroom', 'sport', 'drink'],\n",
       " ['go', 'shop'],\n",
       " ['chair', 'design'],\n",
       " ['ai', 'grass', 'need'],\n",
       " ['wood', 'fan'],\n",
       " ['mind'],\n",
       " ['get', 'today', 'licen', 'think', 'i', 'd', 'day', 'present'],\n",
       " ['eat'],\n",
       " ['danc'],\n",
       " ['was', 'high', 'qualiti', 'littl', 'paint'],\n",
       " ['make', 'milk', 'tea', 'leave', 'layer', 'come'],\n",
       " ['emma', 'amend', 'truck', 'ralli'],\n",
       " ['bu'],\n",
       " ['real', 'panda', 'mascot'],\n",
       " ['happi'],\n",
       " ['clinic', 'worker', 'sick', 'father', 'surpris', 'daughter', 'we', 'd'],\n",
       " ['snail', 'mushroom'],\n",
       " ['bill', 'creat', 'pot'],\n",
       " ['type', 'car', 'park', 'lot'],\n",
       " ['bull', 'suppli', 'month'],\n",
       " ['coal', 'lay', 'counti'],\n",
       " ['sea'],\n",
       " ['poster', 'illeg', 'govern', 'translat'],\n",
       " ['photo', 'hor', 'wear', 'metal'],\n",
       " ['cloud', 'friendli', 'ghost'],\n",
       " ['river', 'surfer'],\n",
       " ['light', 'year', 'birthday', 'candl'],\n",
       " ['coloni', 'poster', 'communist', 'parti', 'x'],\n",
       " ['tree', 'sign'],\n",
       " ['get', 'head', 'road'],\n",
       " ['law', 'pope'],\n",
       " ['govern', 'ban', 'popular', 'greet'],\n",
       " ['bell', 'pepper', 'grow', 'insid'],\n",
       " ['senat', 'chang', 'un', 'conspiraci'],\n",
       " ['cool', 'leav', 'steam'],\n",
       " ['child'],\n",
       " ['captain', 'hit', 'tree'],\n",
       " ['dip', 'sign'],\n",
       " ['tree', 'stump', 'grow', 'bar', 'fenc'],\n",
       " ['shirt', 'recip', 'tag'],\n",
       " ['wing', 'surfac'],\n",
       " ['vote', 'kill', 'presidenti', 'elect'],\n",
       " ['polic', 'investig', 'assault', 'apart', 'standoff', 'oak', 'cliff'],\n",
       " ['poor', 'see'],\n",
       " ['marriag', 'fruit', 'suspici', 'guy', 'girl'],\n",
       " ['high',\n",
       "  'popul',\n",
       "  'foreign',\n",
       "  'languag',\n",
       "  'live',\n",
       "  'district',\n",
       "  'elementari',\n",
       "  'school'],\n",
       " ['throw'],\n",
       " ['happi', 'elev'],\n",
       " ['fifth', 'degre', 'burn'],\n",
       " ['there', 'thing', 'wing'],\n",
       " ['guy', 'strawberri'],\n",
       " ['school'],\n",
       " ['think', 'come', 'intellig'],\n",
       " ['walk'],\n",
       " ['bike'],\n",
       " ['shave', 'support', 'cancer'],\n",
       " ['way'],\n",
       " ['end', 'hous', 'window', 'chocol', 'factori'],\n",
       " ['fight', 'black', 'snake'],\n",
       " ['neon', 'color', 'ice', 'tea'],\n",
       " ['stock', 'lot', 'weird', 'stuff', 'vend', 'machin', 'work'],\n",
       " ['friend', 'terribl', 'ti', 'beach'],\n",
       " ['scissor', 'paper'],\n",
       " ['lake'],\n",
       " ['ca', 'wait', 'season', 'hit'],\n",
       " ['littl', 'tough', 'avoid'],\n",
       " ['warn', 'drink', 'care'],\n",
       " ['coke', 'label'],\n",
       " ['map', 'outsid'],\n",
       " ['presid', 'small', 'base', 'circa'],\n",
       " ['suppli', 'democraci', 'larri', 'law', 'ti'],\n",
       " ['far'],\n",
       " ['steel', 'key', 'alli'],\n",
       " ['ami', 'fight', 'everyday'],\n",
       " ['way', 'ice', 'cube', 'freeze'],\n",
       " ['stick', 'trump'],\n",
       " ['leg', 'strang', 'tail'],\n",
       " ['eggplant', 'buy'],\n",
       " ['hulk'],\n",
       " ['know', 'licen', 'glow', 'flash'],\n",
       " ['mark', 'leg'],\n",
       " ['guy', 'mari'],\n",
       " ['final'],\n",
       " ['declar', 'independ'],\n",
       " ['green', 'sauc'],\n",
       " ['kick'],\n",
       " ['attack', 'rubber', 'snake'],\n",
       " ['trump', 'visit', 'flood', 'continu', 'rise'],\n",
       " ['player',\n",
       "  'world',\n",
       "  'cup',\n",
       "  'birth',\n",
       "  'child',\n",
       "  'say',\n",
       "  'everybodi',\n",
       "  'chanc',\n",
       "  'there',\n",
       "  'day',\n",
       "  'life',\n",
       "  'bear'],\n",
       " ['plane', 'south', 'sun'],\n",
       " ['pot', 'alien', 'face'],\n",
       " ['troll', 'hand'],\n",
       " ['car', 'circa'],\n",
       " ['drone', 'help', 'rescu', 'veteran', 'trap', 'flood'],\n",
       " ['babi', 'lie'],\n",
       " ['concret', 'shoot', 'live', 'room', 'carpet'],\n",
       " ['run', 'montana'],\n",
       " ['fan', 'art'],\n",
       " ['basic', 'tri', 'wink'],\n",
       " ['laugh'],\n",
       " ['colorado'],\n",
       " ['academi', 'class', 'pencil', 'case'],\n",
       " ['monkey', 'ride', 'goat'],\n",
       " ['flash', 'sit'],\n",
       " ['moth', 'crawl', 'carpet'],\n",
       " ['toy', 'hor', 'shadow', 'happi', 'penguin'],\n",
       " ['car', 'ridicul', 'small'],\n",
       " ['oak', 'island', 'special', 'boy'],\n",
       " ['what', 'good'],\n",
       " ['state', 'waterfal'],\n",
       " ['expand', 'surveil', 'right', 'leav', 'offic'],\n",
       " ['mind', 'product', 'get', 'far'],\n",
       " ['leav'],\n",
       " ['help', 'win', 'bet', 'face'],\n",
       " ['guitar'],\n",
       " ['oil'],\n",
       " ['mark'],\n",
       " ['pizza',\n",
       "  'robberi',\n",
       "  'suspect',\n",
       "  'question',\n",
       "  'employe',\n",
       "  'fatal',\n",
       "  'shoot',\n",
       "  'son',\n",
       "  'head'],\n",
       " ['good', 'evil'],\n",
       " ['hurt'],\n",
       " ['oh'],\n",
       " ['fed', 'wall', 'street'],\n",
       " ['rare', 'pictur'],\n",
       " ['melt', 'liquid', 'combin', 'outsid', 'layer', 'copper', 'creat', 'thin'],\n",
       " ['day', 'sit', 'suprem', 'court', 'c'],\n",
       " ['opposit', 'leader', 'shake'],\n",
       " ['work'],\n",
       " ['old', 'pictur', 'dad', 'draw', 'paint', 'print'],\n",
       " ['run', 'inflat', 'suit'],\n",
       " ['real', 'star'],\n",
       " ['friend', 'hold'],\n",
       " ['shall', 'pass'],\n",
       " ['colleg', 'vend', 'machin'],\n",
       " ['trump', 'right', 'make', 'mistak'],\n",
       " ['low', 'rider', 'style'],\n",
       " ['love'],\n",
       " ['film', 'coffe', 'counter', 'perfectli'],\n",
       " ['long'],\n",
       " ['run', 'futur', 'thing'],\n",
       " ['come', 'bear'],\n",
       " ['door', 'handl'],\n",
       " ['sculptur'],\n",
       " ['need', 'lift'],\n",
       " ['decid', 'wo', 'wear', 'pin', 'chest'],\n",
       " ['hold', 'nation', 'championship', 'trophi'],\n",
       " ['day', 'long', 'quiz', 'fall'],\n",
       " ['late', 'countri', 'plastic', 'ban', 'st', 'produc', 'sell', 'use'],\n",
       " ['uncl', 'billi', 'contest'],\n",
       " ['world', 'place', 'know'],\n",
       " ['right', 'place'],\n",
       " ['toy', 'buy', 'piec'],\n",
       " ['hey', 'big', 'announc'],\n",
       " ['bomber', 'submarin', 'second', 'war'],\n",
       " ['water', 'pictur'],\n",
       " ['ladi', 'winter'],\n",
       " ['coffe', 'shop', 'stack', 'seat'],\n",
       " ['that', 'busi'],\n",
       " ['machin', 'water'],\n",
       " ['brave', 'soldier', 'ground', 'protect', 'injur'],\n",
       " ['light', 'right'],\n",
       " ['shall', 'drive', 'carl'],\n",
       " ['understand', 'student', 'movement'],\n",
       " ['trump', 'tri', 'kiss', 'wife'],\n",
       " ['pope', 'parrot', 'belong', 'male'],\n",
       " ['polic', 'offic', 'nur', 'fire', 'medic', 'job'],\n",
       " ['stuf', 'ani', 'come'],\n",
       " ['great', 'shop'],\n",
       " ['good', 'boy'],\n",
       " ['long', 'bill', 'wood', 'grain'],\n",
       " ['judg', 'vote', 'regist', 'motor', 'vehicl'],\n",
       " ['teacher', 'plane', 'give', 'cash'],\n",
       " ['everybodi'],\n",
       " ['spend', 'twice', 'ti', 'ago'],\n",
       " ['collect'],\n",
       " ['smooth'],\n",
       " ['figur'],\n",
       " ['monk', 'come', 'life'],\n",
       " ['work', 'hose', 'creepi'],\n",
       " ['come', 'soon', 'theater', 'near'],\n",
       " ['tradit', 'freedom', 'day', 'rais', 'earth', 'flag'],\n",
       " ['bad', 'zero'],\n",
       " ['twitter', 'account', 'hack', 'tri'],\n",
       " ['spot', 'car', 'way', 'home', 'know', 'actual', 'real'],\n",
       " ['life', 'final', 'free', 'group', 'open', 'sea'],\n",
       " ['grumpi', 'ghost', 'lobbi', 'today'],\n",
       " ['meet', 'bet', 'that', 'cute', 'stori', 'huh'],\n",
       " ['bird', 'hand', 'worth', 'bush'],\n",
       " ['tini', 'littl', 'van', 'japan'],\n",
       " ['fool', 'fat'],\n",
       " ['bottl', 'happi', 'open', 'beer'],\n",
       " ['fix'],\n",
       " ['throw', 'marijuana'],\n",
       " ['pictur', 'rapper', 'drake', 'controversi', 'conver'],\n",
       " ['brown', 'bear', 'bath', 'water'],\n",
       " ['hell', 'come'],\n",
       " ['stall', 'reflect'],\n",
       " ['littl', 'girl', 'dress', 'silent', 'bob'],\n",
       " ['planet'],\n",
       " ['video', 'content', 'republ', 'china'],\n",
       " ['forest', 'guardian'],\n",
       " ['huge', 'kitti'],\n",
       " ['take', 'cocain', 'play'],\n",
       " ['popular', 'hous', 'style'],\n",
       " ['big', 'basketbal'],\n",
       " ['watermelon'],\n",
       " ['old', 'charger', 'approv'],\n",
       " ['lay', 'rest', 'privat', 'ceremoni'],\n",
       " ['movi', 'poster'],\n",
       " ['nation', 'favorit', 'wo', 'affect', 'net', 'neutral', 'repeal'],\n",
       " ['stain', 'trash', 'left', 'ground', 'ancient', 'cave', 'draw', 'speci'],\n",
       " ['save', 'adult'],\n",
       " ['good', 'thing', 'see', 'day'],\n",
       " ['ga', 'near', 'offic'],\n",
       " ['remain'],\n",
       " ['bag', 'water'],\n",
       " ['squar'],\n",
       " ['bloom', 'cherri'],\n",
       " ['govern', 'murder', 'agent', 'soil'],\n",
       " ['intern',\n",
       "  'airport',\n",
       "  'short',\n",
       "  'stori',\n",
       "  'dispen',\n",
       "  'push',\n",
       "  'minut',\n",
       "  'button',\n",
       "  'come',\n",
       "  'receipt'],\n",
       " ['credit', 'union', 'social', 'ament', 'turn', 'success'],\n",
       " ['know'],\n",
       " ['doggo', 'wo', 'bark'],\n",
       " ['jersey', 'offic', 'amid', 'administr', 'counti', 'polit'],\n",
       " ['tree', 'owner'],\n",
       " ['suspici', 'hous', 'colorado', 'ago'],\n",
       " ['donat', 'chariti', 'know', 'use', 'write', 'believ'],\n",
       " ['far', 'bad'],\n",
       " ['player', 'sword', 'art', 'incid', 'game'],\n",
       " ['lid', 'friendli', 'straw', 'featur', 'cardboard', 'tast', 'paper'],\n",
       " ['court', 'file', 'detail', 'role', 'race'],\n",
       " ['watch'],\n",
       " ['snow', 'monster', 'eat', 'car'],\n",
       " ['offic'],\n",
       " ['miss', 'photo', 'crown'],\n",
       " ['health', 'law', 'tax', 'penalti', 'ill', 'million'],\n",
       " ['water'],\n",
       " ['ca', 'explain'],\n",
       " ['bathroom', 'floor', 'show'],\n",
       " ['red', 'armi', 'fleet', 'guard'],\n",
       " ['way', 'ruler'],\n",
       " ['death', 'circa'],\n",
       " ['satellit', 'photo'],\n",
       " ['black', 'white'],\n",
       " ['hey', 'everybodi', 'bob'],\n",
       " ['bottl', 'peel', 'away', 'sticker', 'bare', 'visibl'],\n",
       " ['hotel', 'room', 'silver', 'book', 'holi'],\n",
       " ['park', 'zoo', 'babi', 'camel'],\n",
       " ['record', 'consol', 'big', 'ti'],\n",
       " ['kit'],\n",
       " ['chuck', 'cement'],\n",
       " ['recent', 'album', 'follow', 'stori', 'line', 'cover'],\n",
       " ['final', 'form'],\n",
       " ['subway', 'bench', 'differ', 'seat', 'peopl'],\n",
       " ['world', 'record', 'lift', 'later', 'take', 'perform'],\n",
       " ['wolf', 'wall', 'street', 'edit', 'featur', 'sex'],\n",
       " ['insid'],\n",
       " ['michigan', 'compani', 'peopl', 'marijuana', 'book'],\n",
       " ['white', 'million', 'shoot'],\n",
       " ['grey'],\n",
       " ['readi', 'die', 'freedom'],\n",
       " ['stand', 'old'],\n",
       " ['problem', 'shell'],\n",
       " ['ford', 'base', 'set', 'empir'],\n",
       " ['trap'],\n",
       " ['catch', 'mid', 'yawn'],\n",
       " ['motorcycl',\n",
       "  'accid',\n",
       "  'ago',\n",
       "  'race',\n",
       "  'marathon',\n",
       "  'chair',\n",
       "  'donat',\n",
       "  'use',\n",
       "  'futur'],\n",
       " ['go', 'wild'],\n",
       " ['fire', 'liber', 'use'],\n",
       " ['combin'],\n",
       " ['cop', 'elderli', 'steal', 'engag', 'ring'],\n",
       " ['supper'],\n",
       " ['colleg', 'footbal', 'player', 'sport', 'condit', 'team', 'hi'],\n",
       " ['insid'],\n",
       " ['major', 'drug', 'distribut', 'compani', 'crisi'],\n",
       " ['trump', 'sex', 'tape', 'stormi', 'circa'],\n",
       " ['crisi', 'presid', 'elect'],\n",
       " ['kind', 'sir', 'stop', 'step', 'face'],\n",
       " ['execut', 'idea', 'board'],\n",
       " ['tri', 'scari'],\n",
       " ['number', 'flight', 'coloni'],\n",
       " ['special', 'babi', 'water'],\n",
       " ['sacrific', 'god'],\n",
       " ['vine'],\n",
       " ['sign', 'railway', 'station', 'fine', 'we', 've'],\n",
       " ['stori', 'build', 'elev'],\n",
       " ['state', 'medium', 'missil', 'attack', 'air', 'base'],\n",
       " ['bomber', 'drop', 'air', 'base'],\n",
       " ['war', 'world', 'electr'],\n",
       " ['garag'],\n",
       " ['woman'],\n",
       " ['attempt'],\n",
       " ['get', 'big'],\n",
       " ['woman', 'tattoo', 'rob', 'store', 'polic'],\n",
       " ['mail'],\n",
       " ['microwav', 'oven', 'heat', 'power'],\n",
       " ['photogen', 'grasshopp'],\n",
       " ['hous', 'water', 'tower', 'stay', 'holiday'],\n",
       " ['chicken'],\n",
       " ['thank', 'thread', 'get', 'son', 'graduat', 'high', 'school'],\n",
       " ['bird', 'add', 'water'],\n",
       " ['seat', 'fate'],\n",
       " ['chang'],\n",
       " ['beg', 'belli'],\n",
       " ['fork', 'hold', 'lid', 'cup', 'today', 'outsid', 'snap'],\n",
       " ['individu', 'south', 'clown'],\n",
       " ['leader'],\n",
       " ['happi'],\n",
       " ['player'],\n",
       " ['u'],\n",
       " ['allegedli',\n",
       "  'brutal',\n",
       "  'prison',\n",
       "  'guard',\n",
       "  'day',\n",
       "  'fire',\n",
       "  'depart',\n",
       "  'secretari',\n",
       "  'connect',\n",
       "  'state'],\n",
       " ['woman', 'park', 'pour', 'drink'],\n",
       " ['childhood', 'photo', 'hand'],\n",
       " ['suprem', 'court', 'pride', 'parad', 'see'],\n",
       " ['babi', 'gecko', 'curtain'],\n",
       " ['white'],\n",
       " ['egg'],\n",
       " ['shade', 'tan', 'get'],\n",
       " ['present'],\n",
       " ['la', 'tale', 'emerg', 'aftermath'],\n",
       " ['daddi', 'long'],\n",
       " ['energi', 'hail', 'freedom', 'ga'],\n",
       " ['lee', 'jack', 'hi'],\n",
       " ['h', 'funer', 'circa'],\n",
       " ['elderli', 'unexpect', 'bond', 'young', 'girl'],\n",
       " ['see'],\n",
       " ['plea', 'enter', 'factori', 'work'],\n",
       " ['figur'],\n",
       " ['eat', 'hi'],\n",
       " ['reactor', 'nomin'],\n",
       " ['super', 'weird'],\n",
       " ['car', 'complet', 'burn'],\n",
       " ['panda', 'bend', 'sidewalk'],\n",
       " ['nake', 'ladi', 'beach'],\n",
       " ['teen', 'cheer', 'homeless'],\n",
       " ['fit'],\n",
       " ['tree', 'branch', 'straight'],\n",
       " ['summer', 'day', 'hot', 'chocol', 'marijuana'],\n",
       " ['devic', 'low', 'wall', 'harbor'],\n",
       " ['delici', 'tree', 'work'],\n",
       " ['nose', 'mouth', 'small', 'head'],\n",
       " ['actual', 'fun', 'good', 'sport'],\n",
       " ['win'],\n",
       " ['super', 'inten', 'child'],\n",
       " ['person', 'feel', 'prosthet', 'hand', 'connect', 'brain'],\n",
       " ['dancer', 'alley', 'road'],\n",
       " ['extrem', 'excit', 'hug'],\n",
       " ['fat', 'run', 'hamster', 'photo', 'winner', 'inaugur', 'comedi', 'wildlif'],\n",
       " ['wild', 'parti', 'school', 'birthday'],\n",
       " ['virtual', 'awkward'],\n",
       " ['give'],\n",
       " ['habitat'],\n",
       " ['meet', 'danc', 'team', 'wow'],\n",
       " ['tower'],\n",
       " ['democrat', 'ce'],\n",
       " ['busi', 'take', 'come'],\n",
       " ['photo', 'amir'],\n",
       " ['littl', 'guy', 'cement', 'floor'],\n",
       " ['girl', 'crazi', 'poop', 'face'],\n",
       " ['regret', 'ti', 'dramat'],\n",
       " ['giant', 'tini', 'score'],\n",
       " ['ah', 'swear', 'lie'],\n",
       " ['m', 'white', 'hous'],\n",
       " ['tortois', 'garden'],\n",
       " ['short',\n",
       "  'stori',\n",
       "  'dispen',\n",
       "  'local',\n",
       "  'coffe',\n",
       "  'shop',\n",
       "  'minut',\n",
       "  'long',\n",
       "  'free'],\n",
       " ['attempt', 'read', 'seri', 'basic'],\n",
       " ['intern',\n",
       "  'communist',\n",
       "  'labor',\n",
       "  'movement',\n",
       "  'revolutionari',\n",
       "  'world',\n",
       "  'soviet',\n",
       "  'poster'],\n",
       " ['minist', 'watch', 'footbal', 'match', 'circa'],\n",
       " ['arcad', 'see'],\n",
       " ['resist', 'fold'],\n",
       " ['tortur', 'give'],\n",
       " ['give', 'salut', 'german', 'nation', 'everybodi', 'hi'],\n",
       " ['evil', 'd'],\n",
       " ['system', 'year'],\n",
       " ['know'],\n",
       " ['war'],\n",
       " ['easi', 'spot'],\n",
       " ['go', 'lunch', 'discoveri', 'octopu'],\n",
       " ['field'],\n",
       " ...]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3ae63c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "modell = gensim.models.Word2Vec(titles_corpus, min_count = 1, vector_size= 500)\n",
    "modell.save('word2vec_model_file.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8337d5a0",
   "metadata": {},
   "source": [
    "# Training (Log, Naive, DecT, SVM, Percep, Neural Netw) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "76a526f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= pd.DataFrame()\n",
    "train_data['Word_list']= X_train\n",
    "idx = X_train.index[0]\n",
    "with open('train_word2vec.csv', 'w+') as word2vec_file:\n",
    "    for index, row in train_data.iterrows():\n",
    "        model_vector = (np.mean([modell.wv[token] for token in row['Word_list']], axis=0)).tolist()\n",
    "        if index == idx:\n",
    "            header = \",\".join(str(ele) for ele in range(500))\n",
    "            word2vec_file.write(header)\n",
    "            word2vec_file.write(\"\\n\")\n",
    "\n",
    "        if type(model_vector) is list:  \n",
    "            line1 = \",\".join( [str(vector_element) for vector_element in model_vector] )\n",
    "        else:\n",
    "            line1 = \",\".join([str(0) for i in range(500)])\n",
    "        word2vec_file.write(line1)\n",
    "        word2vec_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "52dd06bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400660, 500)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2f_df = pd.read_csv('train_word2vec.csv')\n",
    "w2f_df.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de79195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LogisticRegression(C=1e5,solver='lbfgs', max_iter=5000)\n",
    "clf=clf.fit(w2f_df.values,y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "648dd643",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data= pd.DataFrame()\n",
    "test_data['Word_list']= X_test\n",
    "idx = X_test.index[0]\n",
    "with open('test_word2vec.csv', 'w+') as word2vec_file:\n",
    "    for index, row in test_data.iterrows():\n",
    "        model_vector = (np.mean([modell.wv[token] for token in row['Word_list']], axis=0)).tolist()\n",
    "        if index == idx:\n",
    "            header = \",\".join(str(ele) for ele in range(500))\n",
    "            word2vec_file.write(header)\n",
    "            word2vec_file.write(\"\\n\")\n",
    "\n",
    "        if type(model_vector) is list:  \n",
    "            line1 = \",\".join( [str(vector_element) for vector_element in model_vector] )\n",
    "        else:\n",
    "            line1 = \",\".join([str(0) for i in range(500)])\n",
    "        word2vec_file.write(line1)\n",
    "        word2vec_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "95bcc900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133554, 500)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2f_test_df = pd.read_csv('test_word2vec.csv')\n",
    "w2f_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fddd1149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('newspap', 0.6760290265083313),\n",
       " ('copi', 0.6708730459213257),\n",
       " ('textbook', 0.6647543907165527),\n",
       " ('page', 0.6197590231895447),\n",
       " ('card', 0.6169708967208862),\n",
       " ('letter', 0.5677825212478638),\n",
       " ('text', 0.5625329613685608),\n",
       " ('album', 0.5575341582298279),\n",
       " ('calendar', 0.5557220578193665),\n",
       " ('error', 0.5418707728385925)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modell.wv.most_similar(\"book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e6f98f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71     70421\n",
      "           1       0.68      0.68      0.68     63133\n",
      "\n",
      "    accuracy                           0.70    133554\n",
      "   macro avg       0.69      0.70      0.69    133554\n",
      "weighted avg       0.70      0.70      0.70    133554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions_w2vec = clf.predict(w2f_test_df.values)\n",
    "print(classification_report(y_test.values,test_predictions_w2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fc84413f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.71      0.69     70421\n",
      "           1       0.65      0.61      0.63     63133\n",
      "\n",
      "    accuracy                           0.66    133554\n",
      "   macro avg       0.66      0.66      0.66    133554\n",
      "weighted avg       0.66      0.66      0.66    133554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_decision_word2vec = DecisionTreeClassifier()\n",
    "clf_decision_word2vec.fit(w2f_df.values,y_train.values)\n",
    "test_decision_word2vec = clf_decision_word2vec.predict(w2f_test_df.values)\n",
    "print(classification_report(y_test.values,test_decision_word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "407f7c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.63     70421\n",
      "           1       0.59      0.57      0.58     63133\n",
      "\n",
      "    accuracy                           0.61    133554\n",
      "   macro avg       0.61      0.61      0.61    133554\n",
      "weighted avg       0.61      0.61      0.61    133554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "Per_clf = Perceptron(tol=1e-3, random_state=0)\n",
    "Per_clf.fit(w2f_df.values,y_train.values)\n",
    "test_Per_word2vec=Per_clf.predict(w2f_test_df.values)\n",
    "print(classification_report(y_test.values,test_Per_word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e9a234",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.base import clone\n",
    "skfolds = StratifiedKFold(n_splits=100, shuffle=True, random_state=42)\n",
    "X=w2f_df\n",
    "Y=y_train\n",
    "NN = MLPClassifier(random_state=1, max_iter=5000, activation='logistic')\n",
    "all_y=[]\n",
    "all_predicted=[]\n",
    "for train_index, test_index in skfolds.split(X, Y):\n",
    "    X_train_folds = X.iloc[train_index]\n",
    "    y_train_folds = Y.iloc[train_index]\n",
    "    X_test_fold = X.iloc[test_index]\n",
    "    y_test_fold = Y.iloc[test_index]\n",
    "    NN.fit(X_train_folds, y_train_folds)\n",
    "    y_pred= NN.predict(X_test_fold)\n",
    "    for i in y_pred:\n",
    "        all_predicted.append(int(i))\n",
    "    for j in y_test_fold:\n",
    "        all_y.append(j)\n",
    "\n",
    "print(classification_report(all_y, all_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "31ea1353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.75      0.74     70421\n",
      "           1       0.72      0.70      0.71     63133\n",
      "\n",
      "    accuracy                           0.73    133554\n",
      "   macro avg       0.73      0.73      0.73    133554\n",
      "weighted avg       0.73      0.73      0.73    133554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "NN = MLPClassifier(random_state=1, max_iter=5000, activation='logistic')\n",
    "NN.fit(w2f_df.values,y_train.values)\n",
    "test_NN_word2vec = NN.predict(w2f_test_df.values)\n",
    "print(classification_report(y_test.values,test_NN_word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a2babd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.53      0.61     70421\n",
      "           1       0.59      0.77      0.67     63133\n",
      "\n",
      "    accuracy                           0.64    133554\n",
      "   macro avg       0.65      0.65      0.64    133554\n",
      "weighted avg       0.66      0.64      0.64    133554\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.53      0.61     70421\n",
      "           1       0.59      0.77      0.67     63133\n",
      "\n",
      "    accuracy                           0.64    133554\n",
      "   macro avg       0.65      0.65      0.64    133554\n",
      "weighted avg       0.66      0.64      0.64    133554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB,MultinomialNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(w2f_df.values,y_train.values)\n",
    "test_gnb_word2vec = gnb.predict(w2f_test_df.values)\n",
    "print(classification_report(y_test.values,test_gnb_word2vec))\n",
    "\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(w2f_df.values,y_train.values)\n",
    "test_ber_word2vec = gnb.predict(w2f_test_df.values)\n",
    "print(classification_report(y_test.values,test_ber_word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5df78bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.70     70421\n",
      "           1       0.67      0.68      0.67     63133\n",
      "\n",
      "    accuracy                           0.69    133554\n",
      "   macro avg       0.69      0.69      0.69    133554\n",
      "weighted avg       0.69      0.69      0.69    133554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "clf.fit(w2f_df,y_train)\n",
    "test_predictions_w2vec = clf.predict(w2f_test_df)\n",
    "print(classification_report(y_test.values,test_predictions_w2vec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
